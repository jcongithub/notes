Hadoop - a framwork for reliable, scalable distributed computing
  1. using simple programming models for the distributed processing of large data sets across clusters of computers
  2. scale up from single servers to thousands of machines
  3. rather than rely on hardware to deliver high-availiability, the framwork itself is designed to detect and handle 
     failures at the application layer, so delivering a highly-available service on top of a cluster of computers

  
Getting Started
1. Hadoop homepage - http://hadoop.apache.org/
2. Setting up a Single Node Cluster on Windows
  a. https://wiki.apache.org/hadoop/Hadoop2OnWindows
  b. 

Hbase - a distributed column-oriented database built on top of HDFS.
HDFS  - Hadoop File System
Hive  - The Apache Hive â„¢ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL.
Spark - a general-purpose distributed data processing engine that is suitable for use in a wide range of circumstances


Cassandra
- NoSQL
- Fault Tolerant
  - Data is automatically replicated to multiple nodes
  - Multiple data center replication
  - Failed nodes can be replaced with no downtime
- Decentralized
  - All nodes are sam
  - Simpler to install and operate
  - no bottleneck


ETL
https://blog.panoply.io/topic/etl
